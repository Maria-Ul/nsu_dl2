{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"sJMPArdPeZbg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"1e958896-0890-408c-93e4-1dd0fac58fb1","executionInfo":{"status":"ok","timestamp":1540995304023,"user_tz":-420,"elapsed":7424,"user":{"displayName":"Pavel Petrochenko","photoUrl":"https://lh4.googleusercontent.com/-T-Fr3-PRKNo/AAAAAAAAAAI/AAAAAAAAAAA/veNhiboaVFE/s64/photo.jpg","userId":"09083772130358405781"}}},"cell_type":"code","source":["!pip install torch\n","!pip install torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n","Collecting pillow>=4.1.1 (from torchvision)\n","  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n","Installing collected packages: pillow\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.3.0\n"],"name":"stdout"}]},{"metadata":{"id":"cEh5k0oee4Ve","colab_type":"text"},"cell_type":"markdown","source":["Давайте напишем какую нить  простую сеть на numpy\n","# Давайте напишем какую нить совсем простую сетку на numpy"]},{"metadata":{"id":"vv0G6R_De_S6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"0e7b825e-0dfb-4515-adb4-f26673f7f54a","executionInfo":{"status":"ok","timestamp":1540995550335,"user_tz":-420,"elapsed":12267,"user":{"displayName":"Pavel Petrochenko","photoUrl":"https://lh4.googleusercontent.com/-T-Fr3-PRKNo/AAAAAAAAAAI/AAAAAAAAAAA/veNhiboaVFE/s64/photo.jpg","userId":"09083772130358405781"}}},"cell_type":"code","source":["import numpy as np\n","from torchvision.datasets import mnist\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import os\n","# N is batch size; D_in is input dimension;\n","# H is hidden dimension; D_out is output dimension.\n","N, D_in, H, D_out = 1, 784, 10, 10\n","\n","# Create random input and output data\n","def toNumpy(x):\n","    return np.array(x,np.float32).flatten()/255.0\n","\n","\n","def label(label):\n","        r=np.zeros(10,np.float32);\n","        r[label]=1.0;\n","        return r;\n","tr=mnist.FashionMNIST(os.path.curdir+\"/fmnist\",download=True,transform=toNumpy,target_transform=label,train=True)\n","\n","\n","# Randomly initialize weights\n","w1 = np.random.randn(D_in, H)\n","w2 = np.random.randn(H, D_out)\n","\n","learning_rate = 1e-6\n","\n","num=0;\n","for i_batch, sample_batched in enumerate(tr):\n","    # Forward pass: compute predicted y\n","    x=np.expand_dims(sample_batched[0],axis=0)\n","    y=np.expand_dims(sample_batched[1],axis=0)\n","    h = x.dot(w1)\n","    h_relu = np.maximum(h, 0)\n","    y_pred = h_relu.dot(w2)\n","\n","    # Compute and print loss\n","    loss = np.square(y_pred - y).sum()\n","    if num%10000==0:\n","      print(loss)\n","    num=num+1\n","    # Backprop to compute gradients of w1 and w2 with respect to loss\n","    grad_y_pred = 2.0 * (y_pred - y)\n","    grad_w2 = h_relu.T.dot(grad_y_pred)\n","    grad_h_relu = grad_y_pred.dot(w2.T)\n","    grad_h = grad_h_relu.copy()\n","    grad_h[h < 0] = 0\n","    grad_w1 = x.T.dot(grad_h)\n","\n","    # Update weights\n","    w1 -= learning_rate * grad_w1\n","    w2 -= learning_rate * grad_w2"],"execution_count":4,"outputs":[{"output_type":"stream","text":["8104.842525402983\n","9.890480577252786\n","1.0\n","1.0\n","1.0\n","1.0\n"],"name":"stdout"}]},{"metadata":{"id":"qHWuW6-pfnlc","colab_type":"text"},"cell_type":"markdown","source":["О кей замечательно а зачем нам тогда torch, давайте попробуем написать тоже самое на нем\n","# Как то очень громоздко, да и ускорителя хочется, давайте попробуем PyTorch"]},{"metadata":{"id":"eSCsmDfCfvf0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"3a9e3bd0-6b90-4e27-d493-6e50560455d8","executionInfo":{"status":"ok","timestamp":1540995623778,"user_tz":-420,"elapsed":10948,"user":{"displayName":"Pavel Petrochenko","photoUrl":"https://lh4.googleusercontent.com/-T-Fr3-PRKNo/AAAAAAAAAAI/AAAAAAAAAAA/veNhiboaVFE/s64/photo.jpg","userId":"09083772130358405781"}}},"cell_type":"code","source":["dtype = torch.float32\n","device = torch.device(\"cpu\")\n","dataloader=DataLoader(tr,batch_size=4)\n","\n","w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n","w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n","\n","for i_batch, sample_batched in enumerate(dataloader):\n","    # Forward pass: compute predicted y\n","    x=sample_batched[0]\n","    y=sample_batched[1]\n","    # Forward pass: compute predicted y\n","    h = x.mm(w1)\n","    h_relu = h.clamp(min=0)\n","    y_pred = h_relu.mm(w2)\n","\n","    # Compute and print loss\n","    loss = (y_pred - y).pow(2).sum().item()\n","    if num%1000==0:\n","      print(loss)\n","    num=num+1\n","\n","    # Backprop to compute gradients of w1 and w2 with respect to loss\n","    grad_y_pred = 2.0 * (y_pred - y)\n","    grad_w2 = h_relu.t().mm(grad_y_pred)\n","    grad_h_relu = grad_y_pred.mm(w2.t())\n","    grad_h = grad_h_relu.clone()\n","    grad_h[h < 0] = 0\n","    grad_w1 = x.t().mm(grad_h)\n","\n","    # Update weights using gradient descent\n","    w1 -= learning_rate * grad_w1\n","    w2 -= learning_rate * grad_w2"],"execution_count":5,"outputs":[{"output_type":"stream","text":["15009.474609375\n","1714.2652587890625\n","357.0181884765625\n","39.878719329833984\n","287.02288818359375\n","595.791015625\n","20.413578033447266\n","48.27613830566406\n","77.92149353027344\n","91.75447082519531\n","7.335393905639648\n","113.30887603759766\n","9.752111434936523\n","80.4443359375\n","7.729575157165527\n"],"name":"stdout"}]},{"metadata":{"id":"93XSfNNhfz3y","colab_type":"text"},"cell_type":"markdown","source":["Какой то очень похожий код получился, в чем же соль?\n","# Autograd"]},{"metadata":{"id":"7nFEovG7gAUx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"b4d866ec-e538-4c71-f904-1dec2fda9566","executionInfo":{"status":"ok","timestamp":1540995696706,"user_tz":-420,"elapsed":13937,"user":{"displayName":"Pavel Petrochenko","photoUrl":"https://lh4.googleusercontent.com/-T-Fr3-PRKNo/AAAAAAAAAAI/AAAAAAAAAAA/veNhiboaVFE/s64/photo.jpg","userId":"09083772130358405781"}}},"cell_type":"code","source":["w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n","w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n","\n","for i_batch, sample_batched in enumerate(dataloader):\n","    # Forward pass: compute predicted y\n","    x=sample_batched[0]\n","    y=sample_batched[1]\n","    # Forward pass: compute predicted y\n","    h = x.mm(w1)\n","    h_relu = h.clamp(min=0)\n","    y_pred = h_relu.mm(w2)\n","\n","    # Compute and print loss\n","    loss = (y_pred - y).pow(2).sum()\n","    if num%1000==0:\n","      print(loss.item())\n","    num = num + 1\n","    loss.backward()\n","\n","    with torch.no_grad():\n","        w1 -= learning_rate * w1.grad\n","        w2 -= learning_rate * w2.grad\n","\n","        # Manually zero the gradients after updating weights\n","        w1.grad.zero_()\n","        w2.grad.zero_()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["47525.921875\n","638.318115234375\n","155.62283325195312\n","289.56805419921875\n","23.228336334228516\n","527.4720458984375\n","4.0\n","90.97450256347656\n","352.0081787109375\n","4.673168659210205\n","137.875732421875\n","20.235248565673828\n","287.8556213378906\n","25.872745513916016\n","34.8391227722168\n"],"name":"stdout"}]},{"metadata":{"id":"RkIS8kPBgHzP","colab_type":"text"},"cell_type":"markdown","source":["Уже лучше но может быть в библиотеке есть еще какие нить полезные абстракции?\n","# Welcome nn.modules"]},{"metadata":{"id":"DJGqqNfAgcHP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"4e69ee37-7785-4f02-8f43-214a63b224c1","executionInfo":{"status":"ok","timestamp":1540995829014,"user_tz":-420,"elapsed":16111,"user":{"displayName":"Pavel Petrochenko","photoUrl":"https://lh4.googleusercontent.com/-T-Fr3-PRKNo/AAAAAAAAAAI/AAAAAAAAAAA/veNhiboaVFE/s64/photo.jpg","userId":"09083772130358405781"}}},"cell_type":"code","source":["model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",")\n","loss_fn = torch.nn.MSELoss(reduction='sum')\n","\n","for i_batch, sample_batched in enumerate(dataloader):\n","    # Forward pass: compute predicted y\n","    x=sample_batched[0]\n","    y=sample_batched[1]\n","    y_pred = model(x)\n","\n","    # Compute and print loss\n","    loss = loss_fn(y_pred, y)\n","    model.zero_grad()\n","    if num%1000==0:\n","      print(loss.item())\n","    num=num+1\n","    loss.backward()\n","\n","    with torch.no_grad():\n","        for param in model.parameters():\n","            param -= learning_rate * param.grad"],"execution_count":7,"outputs":[{"output_type":"stream","text":["4.2322163581848145\n","5.118720054626465\n","3.7685601711273193\n","5.09650182723999\n","3.7381396293640137\n","3.3226401805877686\n","3.92453932762146\n","4.040871620178223\n","4.804718017578125\n","3.307461738586426\n","4.164682865142822\n","3.152167558670044\n","3.3927435874938965\n","3.3534796237945557\n","3.310598850250244\n"],"name":"stdout"}]},{"metadata":{"id":"uBWtJdHSgqlF","colab_type":"text"},"cell_type":"markdown","source":["А нужно ли самим апдейтить веса?"]},{"metadata":{"id":"oU6Q3W2sgv4d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"e9c7e88a-6367-4bce-fb83-03854f63ef90","executionInfo":{"status":"ok","timestamp":1540995897024,"user_tz":-420,"elapsed":17580,"user":{"displayName":"Pavel Petrochenko","photoUrl":"https://lh4.googleusercontent.com/-T-Fr3-PRKNo/AAAAAAAAAAI/AAAAAAAAAAA/veNhiboaVFE/s64/photo.jpg","userId":"09083772130358405781"}}},"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","for i_batch, sample_batched in enumerate(dataloader):\n","    # Forward pass: compute predicted y\n","    x=sample_batched[0]\n","    y=sample_batched[1]\n","    y_pred = model(x)\n","\n","    # Compute and print loss\n","    loss = loss_fn(y_pred, y)\n","    if num%1000==0:\n","      print(loss.item())\n","    num=num+1\n","\n","    optimizer.zero_grad()\n","\n","    # Backward pass: compute gradient of the loss with respect to model\n","    # parameters\n","    loss.backward()\n","\n","    # Calling the step function on an Optimizer makes an update to its\n","    # parameters\n","    optimizer.step()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["3.6236021518707275\n","3.583860158920288\n","3.476802110671997\n","4.218475341796875\n","3.53511905670166\n","2.871598243713379\n","3.5844526290893555\n","3.619049310684204\n","4.245276927947998\n","3.0241246223449707\n","3.4729809761047363\n","2.886005401611328\n","3.2664787769317627\n","2.715991258621216\n","2.8421385288238525\n"],"name":"stdout"}]},{"metadata":{"id":"a1Nc0SbJg6Te","colab_type":"text"},"cell_type":"markdown","source":["А если мы хотим свой модуль?\n","# Как написать кастомный модуль"]},{"metadata":{"id":"S7gXdBNZhA8A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"3151b9d6-7340-4bf9-e41f-ae08b4c9ae9c","executionInfo":{"status":"ok","timestamp":1540995961149,"user_tz":-420,"elapsed":14566,"user":{"displayName":"Pavel Petrochenko","photoUrl":"https://lh4.googleusercontent.com/-T-Fr3-PRKNo/AAAAAAAAAAI/AAAAAAAAAAA/veNhiboaVFE/s64/photo.jpg","userId":"09083772130358405781"}}},"cell_type":"code","source":["class TwoLayerNet(torch.nn.Module):\n","    def __init__(self, D_in, H, D_out):\n","        \"\"\"\n","        In the constructor we instantiate two nn.Linear modules and assign them as\n","        member variables.\n","        \"\"\"\n","        super(TwoLayerNet, self).__init__()\n","        self.linear1 = torch.nn.Linear(D_in, H)\n","        self.linear2 = torch.nn.Linear(H, D_out)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        In the forward function we accept a Tensor of input data and we must return\n","        a Tensor of output data. We can use Modules defined in the constructor as\n","        well as arbitrary operators on Tensors.\n","        \"\"\"\n","        h_relu = self.linear1(x).clamp(min=0)\n","        y_pred = self.linear2(h_relu)\n","        return y_pred\n","\n","\n","\n","# Construct our model by instantiating the class defined above\n","model = TwoLayerNet(D_in, H, D_out)\n","\n","criterion = torch.nn.MSELoss(reduction='sum')\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n","for i_batch, sample_batched in enumerate(dataloader):\n","    # Forward pass: Compute predicted y by passing x to the model\n","    y_pred = model(x)\n","\n","    # Compute and print loss\n","    loss = criterion(y_pred, y)\n","    if num%1000==0:\n","      print(loss.item())\n","    num=num+1   \n","    # Zero gradients, perform a backward pass, and update the weights.\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["4.695863246917725\n","1.2893601655960083\n","0.7731939554214478\n","0.43944790959358215\n","0.23118431866168976\n","0.11921994388103485\n","0.06225814297795296\n","0.03325456380844116\n","0.018173672258853912\n","0.010128169320523739\n","0.00573276961222291\n","0.0032822296489030123\n","0.0018452862277626991\n","0.0010423548519611359\n","0.0005955630913376808\n"],"name":"stdout"}]}]}